# Event Payload ETL Pipeline

A high-performance Python-based ETL pipeline designed to ingest complex, nested JSON event data and transform it into structured, analytics-ready CSV files. This project demonstrates best practices in data engineering, including nested JSON parsing, timezone manipulation, and strict adherence to data formatting requirements.

## ğŸš€ Overview

Modern applications often generate telemetry and event data in semi-structured JSON formats. This pipeline targets a specific scenario for **Chama**, a data-oriented company, where raw event logs from App and API usage need to be flattened into relational tables for business intelligence and data analysis.

### Features
- **JSON Flattening**: Deserializes complex, nested payloads into flat structures.
- **Timezone Management**: Automatically converts UTC timestamps to Brasilian Time (UTC-3) for localized reporting.
- **Strict Data Types**: Ensures specific quoting conventions (quoted strings, unquoted numerics/booleans) to meet target system requirements.
- **Scalable Design**: Uses Python and Pandas for efficient data manipulation.

## ğŸ› ï¸ Tech Stack
- **Language**: Python 3.x
- **Core Library**: [Pandas](https://pandas.pydata.org/)
- **Data Formats**: JSON (Input), CSV (Output)
- **Time Management**: `datetime` with UTC-3 conversion.

## ğŸ“ Project Structure
```text
.
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ case.json           # Raw input data
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ CuratedOfferOptions.csv
â”‚   â”œâ”€â”€ DynamicPriceOption.csv
â”‚   â””â”€â”€ DynamicPriceRange.csv
â”œâ”€â”€ etl_pipeline.py         # Main ETL logic
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ README.md
```

## âš™ï¸ Logic & Implementation

The pipeline processes three distinct types of data extracted from the `Payload` field of each event:

1.  **CuratedOfferOptions**: Detailed offer data including dealer information, product brands, and "winner" flags.
2.  **DynamicPriceOption**: Optimization results for specific unique options.
3.  **DynamicPriceRange**: Global and recommended price ranges generated by algorithms.

### Thought Process:
- **Resilience**: Implements `try-except` blocks for JSON decoding to handle potential malformed payloads.
- **Modularization**: Decoupled timezone conversion and file saving logic for maintainability.
- **Quality Control**: Uses Pandas' `QUOTE_NONNUMERIC` to ensure data integrity during the export phase.

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8+
- pip

### Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/event-payload-etl-pipeline.git
   cd event-payload-etl-pipeline
   ```
2. Set up a virtual environment:
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### Running the Pipeline
Simply execute the main script:
```bash
python3 etl_pipeline.py
```
The processed CSVs will be generated in the `output/` directory.

## ğŸ“Š Sample Output
| CurationProvider | OfferId | DealerId | IsWinner | EnqueuedTimeSP |
| :--- | :--- | :--- | :--- | :--- |
| "ByPrice" | "149f0e53..." | "6517" | True | 25/08/2021 |

---
*Created as a demonstration of Data Engineering and Python proficiency.*
